---
title: "Proyecto Final Analítica basada en árboles de clasificación y regresión"
author: "Alejandro Noel Hernández Gutiérrez"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Proyecto Final}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Descripción del problema

El set de datos tiene su origen en el National Institute of Diabetes and Digestive and Kidney

Diseases.

El objetivo del presente proyecto es predecir si un paciente tiene diabetes utilizando random forest y arboles de clasificación de 3 paqueterías diferentes.

El set de datos está acotado a mujeres con al menos 21 años de edad pertenecientes a una etnia en la India.

La variable target o independiente es outcome, que indica que el paciente tiene diabetes.

## Descripción del conjunto de datos

| Columnas                 | Descripción                                                                                                                                                                                                                                                                | Clases-rango   |
|----------|----------------------------------------------------|----------|
| Pregnancies              | Número de embarazos                                                                                                                                                                                                                                                        | 0-17           |
| Glucose                  | Nivel de glucosa en la sangre. No es probable glucosa 0 a menos que este muerta (Consultado con lic. Maria Fernanda Hernandez Jimenez, estudiante de medicina de la Universidad de Guadalajara). Por este motivo hay que sustituir los valores faltantes con algun método. | 0-199.         |
| BloodPressure            | Presión arterial en mm/Hg. No es probable presión arteríal 0 a menos que la paciente esté muerta.                                                                                                                                                                          | 0-122.         |
| SkinThickness            | Grosor de la piel en mm. No es probable SkinThickness 0.                                                                                                                                                                                                                   | 0-99.          |
| Insulin                  | Nivel de insulina en la sangre en U/mL. Unidades entre minilitro el valor 0 no es válido.                                                                                                                                                                                  | 0-846          |
| BMI                      | Indice de masa corporal en kg/m2. 0 no tiene sentido.                                                                                                                                                                                                                      | 0-67.10.       |
| DiabetesPedigreeFunction | Probabilidad de diabetes en función de los antecedentes familiares.                                                                                                                                                                                                        | 0.0780-2.4200  |
| Age                      | Edad de la persona.                                                                                                                                                                                                                                                        | 21-81          |
| Outcome                  | Determina si el paciente tiene o no diabetes.                                                                                                                                                                                                                              | [1: si, 0: no] |

# Obtención de datos

```{r}
data <- read.csv("data/diabetes.csv")
head(data)
```

```{r include=FALSE}
# Carga de librerías
library(tidymodels)
library(tidyverse)
library(dplyr) 
library(skimr)
library(DataExplorer)
library(moments) # kurtosis and skewness
library(ggplot2)
library(caret)
library(rpart)
library(kableExtra)
library(ggthemes)
library(dplyr)
library(ggplot2)
library(reshape2)
library(caTools)
library(rpart.plot)
library(tictoc)
library(beepr)
library(xgboost)
library(h2o)
```

# Exploración de datos

## Summary

Pregnancies: La media de los embarazos es de 3. El rango es de 0-17.

Glucose: La media es de 120.9. El rango es de 0-199, se intuye que 0 representa información perdida y se reemplazará por la media.

BloodPressure: La media es de 69.11. El rango es de 0-122. Se intuye que el 0 representa información perdida, se estudiará el caso a continuación. Se observa que generalmente si falta este dato es muy probable que falte la insulina y el grosor de piel (SkinThickness)

SkinThickness La media es de 20.54mm y el rango de 0-99. Nadie puede tener grosor de piel de 0, por lo que habrá que revisar ese dato.

Insulina: La media es de 79.8 y el rango es de 0-846.

BMI: La mediana es 31.99 y el rango es de 0-67.10.

DiabetesPedigreeFunction: La media es de 0.4719 y el rango es de 0.0780-2.4200.

Age: La media es de 33.24 y el rango es de 21- 81 años.

```{r}
knitr::kable(summary(data))
```

## Plot intro

En continuación con el analis se puede observar que aparentemente no hay información perdida, esto es falso porque en algunas columnas el 0 significa que el valor no existe.

```{r, fig.dim = c(8, 6)}
plot_intro(data)
```

## Analisis de la distribución

```{r, fig.dim = c(8, 6)}
plot_bar(data)
```

En este caso notamos que los datos tienen buen balance. De cualquier manera se utilizará más adelante submuestreo para entrenar con datos completamente balanceados.

```{r}
prop.table(table(data$Outcome))
```

## Distribución de variables continuas por medio de histograma

Aquí se ve con claridad que BloodPreassure, BMI, Glucose, Insulin and SkinThickness tienen datos faltantes catalogados como 0 y a simple vista se pueden apreciar como outliers.

```{r, fig.dim = c(8, 6)}
plot_histogram(data)
```

![](http://127.0.0.1:45971/chunk_output/604BF104957fe0a5/46C9959A/ce9qwgf9b0uit/000010.png)

## Kurtosis

Continuando con el análisis de missing fields, se procede a explorar la distribución de los datos. Una distribución uniforme (o kurtosis menor que 1.2) sería candidata a sustitución aleatoria.

Si la distribución resulta ser normal, se procede a buscar valores atipicos. Si no los hay se usa la media, si los hay se usa la mediana porque la media se puede ver afectada.

De la siguiente tabla se infiere que no hay distribución uniforme. Resta revisar los atípicos para decidir.

```{r}
knitr::kable(kurtosis(data))
```

## Boxplot con relación a la variable target

Para la glucosa, los unicos atipicos parecen ser el 0, por lo que la sustitución se hará con la media.

```{r, fig.dim = c(8, 6)}
boxplot(data$Glucose, horizontal = TRUE)
```

Para la BloodPressure, si se presentan algunos otros valores atípicos, por lo que la sustitución de faltantes será con mediana.

```{r, fig.dim = c(8, 6)}
boxplot(data$BloodPressure, horizontal = TRUE)
```

Para el grosor de la piel, se tiene un atipico de 99 que podría afectar un poco, se decide usar la mediana para la sustitución de datos faltantes.

```{r, fig.dim = c(8, 6)}
boxplot(data$SkinThickness, horizontal = TRUE)
```

En este caso se ve que existen muchos casos con 0, 374 para ser exactos. Esto no es válido ya que el rango comienza de nuevo en los 14. 0 son missing fields. Se cambia por la mediana.

```{r, fig.dim = c(8, 6)}
boxplot(data$Insulin, horizontal = TRUE)
```

Para la BMI, si se presentan algunos otros valores atípicos, por lo que la sustitución de faltantes (el caso 0) será con mediana.

```{r, fig.dim = c(8, 6)}
boxplot(data$BMI, horizontal = TRUE)
```

## Análisis de correlación

Podemos encontrar correlaciones interesantes como la edad con el embarazo y la glucosa con el objeto de estudio, pero en esta última indica que es importante para el modelo. No cambios requeridos.

```{r, fig.dim = c(10, 6)}
plot_correlation(na.omit(data), maxcat = 5L)
```

## Duplicados

Es posible observar que no hay duplicados, ya que aplicando un distinct se obtienen la misma cantidad de rows.

```{r}
count <- data %>% distinct() %>% count()
head(count)
```

# Preprocesamiento

En este paso vamos a hacegurarnos que las variables estén en el tipo de dato necesario para el procesamiento.

```{r}
data <- data %>% mutate(Pregnancies      = Pregnancies %>% as.numeric(),
                    Glucose          = Glucose %>% as.numeric(),
                    SkinThickness    = SkinThickness %>% as.numeric(),
                    Insulin          = Insulin %>% as.numeric(),
                    BMI              = BMI %>% as.numeric(),
                    DiabetesPedigreeFunction = DiabetesPedigreeFunction %>% as.numeric(),
                    Age              = Age %>% as.numeric(),
                    Outcome = Outcome %>% as.factor())
```

# Limpieza de datos

Como fue explorado en el capitulo anterior, para algunas variables se utilizará la media y para otras la mediana.

```{r}
# Lo ya visto:
#Glucosa, media. 120.9
#BloodPressure, mediana. 72.0
#SkinThickness, mediana. 23.0
#Insulin, mediana. 30.5
#BMI, mediana. 32.0

data_clean <- data
data_clean$Glucose[data_clean$Glucose==0]             <- 120.9
data_clean$BloodPressure[data_clean$BloodPressure==0] <- 72.0
data_clean$SkinThickness[data_clean$SkinThickness==0] <- 23.0
data_clean$Insulin[data_clean$Insulin == 0]           <- 30.5
data_clean$BMI[data_clean$BMI==0]                     <- 32.0
```

```{r}
# Revisar de nuevo duplicados
count <- data_clean %>% distinct() %>% count()
head(count)
```

Al revisar el histograma con los datos limpios, se puede observar que ya no está el problema de los datos faltantes

```{r, fig.dim = c(8, 6)}
plot_histogram(data_clean)
```

Para confirmarlo, se puede mirar el summary. Los rangos ya están corregidos.

```{r}
# Aqui  la diferencia al aplicar sustitución de datos faltantes
knitr::kable(summary(data_clean))
```

# Subsampling

La idea es entrenar con datos balanceados y hacer test con datos desbalanceados (Distribución en la realidad)

Para esto

-   Se Añade un index al conjunto completo de datos.

-   Se divide en unbalanced_train (80) y unbalanced_test (20).

-   Se balancea el balanced_train (80) con down Sample.

-   Se entrena el modelo con balanced_train.

```{r}
tidy_split <- initial_split(data_clean, prop = 0.8, strata = "Outcome")

unbalanced_train  <- training(tidy_split)
unbalanced_test  <- testing(tidy_split)
```

```{r}
balanced_train <- downSample(unbalanced_train[, -ncol(unbalanced_train)], unbalanced_train$Outcome, yname = "Outcome") # submuestrear la clase mayoritaria
table(balanced_train$Outcome) 
```

Verificamos efectivamente los datos de train están perfectamente balanceados. Parece suficiente entrenar con 428 datos.

```{r}
prop.table(table(balanced_train$Outcome))
```

# Solución random Forest

```{r}
tidy_train <- balanced_train
tidy_test <- unbalanced_test
```

```{r}
model_tidy<- rand_forest(
  mode = "classification",
  mtry = tune(),# hiperparámetros de los features que tenemos N-1 (flag)
  trees = 4 # Random Forest trees
) %>%  set_engine(engine = "ranger",
                  max.depth = tune(),
                  importance = "none", #"impurity"
                  seed = 123 )
```

```{r}
# preprocesado de datos
transformer <- recipe(formula = Outcome ~.,
                      data = tidy_train)

# Validación cruzada 
cv_folds <- vfold_cv(data = tidy_train,
                     v = 5,
                     strata = Outcome)
  

# Workflow. Aqui si hay que cuidar nombre de hiperparámetros en la grid
def_workflow <- workflow() %>%  add_recipe(transformer) %>% 
  add_model(model_tidy)
```

## Hiperparámetros Tidymodels Random Forest

Se escogen solamente estos 2, que ya dejan el modelo muy funcional.

-   **`mtry`**: Es el número de variables aleatorias que se seleccionan para cada árbol. Si se establece en un número pequeño, se utilizarán menos variables para construir cada árbol, lo que podría conducir a una mayor variabilidad en el modelo. Si se establece en un número más grande, se utilizarán más variables, lo que podría mejorar la precisión del modelo, pero también podría hacer que el modelo se ajuste demasiado a los datos de entrenamiento. En este caso, se están probando diferentes valores de **`mtry`**, desde 3 hasta el número de columnas en el conjunto de datos menos uno.

-   **`max.depth`**: Es la profundidad máxima permitida para cada árbol en el modelo. Si se establece en un número pequeño, como 3, el modelo tendrá árboles poco profundos y se evitará el sobreajuste. Si se establece en un número grande, como 10, se permitirán árboles más profundos y el modelo podría ser más preciso, pero también podría sobreajustarse más fácilmente. En este caso, se están probando diferentes valores de profundidad, desde 3 hasta 10.

```{r}
grid_hiper <- expand_grid(
  # Numero de predictores que se muestrearán aleatoriamente en cada división al crear los modelos de árbol:
                    'mtry' = c(3,5,7, ncol(df)-1), 
                    'max.depth' = c(3,5,7,10)) # máxima profundidad
head(grid_hiper)
```

```{r}
# Tunning del grid
grid_fit <- tune_grid(
  object = def_workflow,
  resamples = cv_folds, # validación cruzada
  metrics = metric_set(roc_auc,accuracy), 
  grid = grid_hiper
)
```

```{r}
# Mostramos del grid la mejor configuración utilizado la curva roc
show_best(grid_fit,metric = "roc_auc", n=1)
```

```{r}
best_hiper <- select_best(grid_fit, metric = 'roc_auc')
# Definir MODELO FINAL
final_model_tidy <- finalize_workflow(
  x = def_workflow,
  parameters = best_hiper) %>% 
  fit(data = tidy_train) %>% extract_fit_parsnip()
```

## Predicciones con datos desbalanceados de test

```{r}
# Prediccciones con 
predicts_tidy <- final_model_tidy %>% predict(new_data = tidy_test) # SI/NO

# Agregarle una columna al lado
predicts_tidy <- predicts_tidy %>% bind_cols(tidy_test %>% select(Outcome))
# efectividad del modelo
accuracy_metric <- accuracy(data = predicts_tidy,
                            truth = 'Outcome',
                            estimate = '.pred_class',
                            na_rm = TRUE # no tomar en cuenta NAs
                            )
accuracy_metric
```

## Confusión Matrix de datos desbalanceados de test

```{r}
# Matriz de confusión
# en el caso de no, se equivoca en 9 tiendas. En el caso de si, se equivoca en 10
confu_mat <- conf_mat(
  data = predicts_tidy,
  truth = 'Outcome',
  estimate = '.pred_class'
  )
confu_mat
```

## Error de test

```{r}
accuracy_ <- accuracy_metric$.estimate
# Calcular el error de prueba como 1 - precisión
test_error <- 1 - accuracy_

# Imprimir el error de prueba
cat("Error de prueba:", test_error, "\n")
```

## Predicciones con datos balanceados de train

```{r}
# Prediccciones con 
predicts_tidy <- final_model_tidy %>% predict(new_data = tidy_train) # SI/NO

# Agregarle una columna al lado
predicts_tidy <- predicts_tidy %>% bind_cols(tidy_train %>% select(Outcome))

# efectividad del modelo
accuracy_metric <- accuracy(data = predicts_tidy,
                            truth = 'Outcome',
                            estimate = '.pred_class',
                            na_rm = TRUE # no tomar en cuenta NAs
                            )
accuracy_metric
```

## Confusión matrix con datos balanceados de train

```{r}
# Matriz de confusión
# en el caso de no, se equivoca en 9 tiendas. En el caso de si, se equivoca en 10
confu_mat <- conf_mat(
  data = predicts_tidy,
  truth = 'Outcome',
  estimate = '.pred_class'
  )
confu_mat
```

## Error de train

```{r}
accuracy_ <- accuracy_metric$.estimate
# Calcular el error de prueba como 1 - precisión
train_error <- 1 - accuracy_

# Imprimir el error de entrenamiento
cat("Error de entrenamiento:", train_error, "\n")
```

# Importancia de las variables

En el análisis de importancia de las variables podemos ver que la glucosa, el indice de masa corporal, la edad son muy relevantes para el objeto de estudio.

```{r}
modelo_caret_rf <- train(Outcome ~ ., data = balanced_train, method = "rf") # Random Forest simple caret

imp_var <- varImp(modelo_caret_rf, scale = FALSE) # calcular la importancia de las variables
print(imp_var) # mostrar los resultados
```

# Solución H2o

```{r}
library(h2o)
h2o.init(ip = 'localhost',
         nthreads = -1, # -1 indica que se emplean todos los cores disponibles
         max_mem_size = '6g' # máxima memoria disponible para el cluster
)
```

```{r}
h2o.removeAll()
```

```{r}
# Se mandan datos balanceados para train y desbalanceados para validación y test
data_train_h2o <- as.h2o(x = balanced_train,destination_frame = "data_train_h2o")
data_val_h2o <- as.h2o(x = unbalanced_train,destination_frame = "data_val_h2o")
data_test_h2o <- as.h2o(x = unbalanced_test,destination_frame = "data_test_h2o")
```

## Hiperparámetro H2o

La optimización de hiperparámetros por Grid Search permite entrenar el modelo con diferentes combinaciones y escoger la mejor. Para random forest en H2o elegimos los siguientes:

-   **`ntrees`**: Es el número de árboles que se crearán en el modelo. En este caso, se está iniciando con un solo árbol y luego se probarán diferentes números de árboles en el proceso de ajuste de hiperparámetros. Cuantos más árboles se creen, más preciso será el modelo, pero también podría tardar más tiempo en entrenarse.

-   **`max_depth`**: Es la profundidad máxima permitida para cada árbol en el modelo. Si se establece en un número pequeño, como 1, el modelo tendrá árboles poco profundos y se evitará el sobreajuste. Si se establece en un número grande, como 20, se permitirán árboles más profundos y el modelo podría ser más preciso, pero también podría sobreajustarse más fácilmente. En este caso, se están probando diferentes valores de profundidad, desde 1 hasta 20, en incrementos de 3.

-   **`min_rows`**: Es el número mínimo de observaciones que se permiten en un nodo del árbol. Si se establece en un número pequeño, como 2, se permitirán divisiones más pequeñas y detalladas, lo que podría conducir al sobreajuste. Si se establece en un número más grande, como 50, se requerirá un mayor número mínimo de observaciones para que se realice una división, lo que podría ayudar a evitar el sobreajuste. En este caso, se están probando diferentes valores de número mínimo de observaciones, desde 2 hasta 50, en incrementos de 3.

-   **`sample_rate`**: Es la fracción de observaciones que se utilizan para entrenar cada árbol. Si se establece en 1, se utilizarán todas las observaciones, lo que podría conducir al sobreajuste. Si se establece en un número más pequeño, como 0.55, se utilizará una muestra aleatoria del 55% de las observaciones para entrenar cada árbol, lo que podría ayudar a evitar el sobreajuste. En este caso, se están probando diferentes valores de fracción de muestra, desde 0.55 hasta 0.75, en incrementos de 0.082.

```{r}
# Grid de hiperparámetros h20
grid_h2o_hyperpm <- list(ntrees = 1,
                         max_depth = seq(1,20, by = 3),
                         min_rows = seq(2,50, by = 3),
                         sample_rate = c(0.55,0.632,0.75)
                         )
# Estrategia de busqueda del mejor conjunto de hiperparámetros
searchparam <- list(strategy = "RandomDiscrete",
                    stopping_metric = "AUC",
                    stopping_tolerance = 0.005,
                    stopping_rounds = 10,
                    max_runtime_secs = 600)
```

```{r}
grid <- h2o.grid(algorithm = "randomForest",
                 y = "Outcome",
                 grid_id = "default",
                 training_frame = data_train_h2o,
                 validation_frame = data_val_h2o,
                 nfolds = 5,
                 hyper_params = grid_h2o_hyperpm,
                 search_criteria = searchparam
)
```

```{r}
# Obtener del grid los selected parameters
selectedparam <- h2o.getGrid(grid_id = "default",
                             sort_by = "AUC",
                             decreasing = TRUE
)
```

```{r}
#Obtener el mejor modelo
bestmodel <- h2o.getModel(selectedparam@model_ids[[1]])
```

## Predicciones con datos desbalanceados de test

```{r}

prediction_h2o <-  as_tibble(h2o.predict(object = bestmodel,
                                        newdata = data_test_h2o))
prediction_h2o <- prediction_h2o %>% bind_cols(as.data.frame(data_test_h2o$Outcome))
prediction_h2o <- as.data.frame(prediction_h2o)
indx <- sapply(prediction_h2o, is.factor)
prediction_h2o[indx] <- lapply(prediction_h2o[indx], function(x) as.numeric(x))
head(prediction_h2o)
```

```{r}
cm <- confusionMatrix(as.factor(prediction_h2o$predict),as.factor( prediction_h2o$Outcome))
cm
```

```{r}
# Analizamos como obtener dinamicamente el accuracy
str(cm)
```

## Error con datos desbalanceados de test

```{r}
overall_accuracy <- cm$overall['Accuracy'] 
# Calcular el error de prueba como 1 - precisión
test_error <- 1 - overall_accuracy
# Imprimir el error de prueba
cat("Error de prueba:", test_error, "\n")
```

## Predicciones con datos balanceados de train

```{r}
prediction_h2o <-  as_tibble(h2o.predict(object = bestmodel,
                                        newdata = data_train_h2o))
prediction_h2o <- prediction_h2o %>% bind_cols(as.data.frame(data_train_h2o$Outcome))
prediction_h2o <- as.data.frame(prediction_h2o)
indx <- sapply(prediction_h2o, is.factor)
prediction_h2o[indx] <- lapply(prediction_h2o[indx], function(x) as.numeric(x))
head(prediction_h2o)
```

```{r}
cm <- confusionMatrix(as.factor(prediction_h2o$predict),as.factor( prediction_h2o$Outcome))
cm
```

## Error con datos balanceados de entrenamiento

```{r}
overall_accuracy <- cm$overall['Accuracy'] 
# Calcular el error de entrenamiento como 1 - precisión
train_error <- 1 - overall_accuracy
# Imprimir el error de entrenamiento
cat("Error de entrenamiento:", train_error, "\n")
```

# Solución XGboost

```{r}
xgboost_train <- balanced_train
xgboost_test <- unbalanced_test
```

```{r}
# Se establece una técnica de train control
train_control = trainControl(
  method = "cv", # Tecnica CV se pasará al entrenamiento
  number = 5,    # Es la 'k' en K-fold cross validation
  search = "grid" # Busqueda por Grid
  )
```

## Optimización de hiperparámetros

Al introducir este modelo se puede ahondar un poco en los hiperparámetros elegidos.

La optimización de hiperparámetros por grid search nos permite buscar la mejor combinacion posible.

-   **`max_depth`**: Es la profundidad máxima permitida para cada árbol en el modelo. Si se establece en un número pequeño, como 3, el modelo tendrá árboles poco profundos y se evitará el sobreajuste. Si se establece en un número grande, como 7, se permitirán árboles más profundos y el modelo podría ser más preciso, pero también podría sobreajustarse más fácilmente.

-   **`nrounds`**: Es el número de árboles que se crearán en el modelo. En este caso, se están probando diferentes números de árboles, desde 50 hasta 500, en incrementos de 50. Cuantos más árboles se creen, más preciso será el modelo, pero también podría tardar más tiempo en entrenarse.

-   **`eta`**: También conocido como tasa de aprendizaje, controla la magnitud de la actualización de cada paso de descenso de gradiente. Un valor más bajo de eta significa que el modelo se ajustará más lentamente y de manera más suave, lo que podría ayudar a evitar el sobreajuste, pero también podría ralentizar la convergencia del modelo.

-   **`gamma`**: Es un parámetro de regularización que controla cuánto se necesita que la función de pérdida disminuya para que se considere una división adicional en un nodo del árbol. Un valor más alto de gamma significa que se requerirá una disminución mayor en la función de pérdida para que se realice una división adicional, lo que podría ayudar a evitar el sobreajuste.

-   **`subsample`**: Es la fracción de observaciones que se utilizan para entrenar cada árbol. Si se establece en 1, se utilizarán todas las observaciones, lo que podría conducir al sobreajuste. Si se establece en un número más pequeño, como 0.8, se utilizará una muestra aleatoria del 80% de las observaciones para entrenar cada árbol, lo que podría ayudar a evitar el sobreajuste.

-   **`min_child_weight`**: Es el peso mínimo requerido para que un nodo se divida en dos. Si se establece en un número pequeño, como 1, se permitirán divisiones más pequeñas y detalladas, lo que podría conducir al sobreajuste. Si se establece en un número más grande, como 10, se requerirá un mayor peso mínimo para que se realice una división, lo que podría ayudar a evitar el sobreajuste.

-   **`colsample_bytree`**: Es la fracción de características que se utilizan para entrenar cada árbol. Si se establece en 1, se utilizarán todas las características, lo que podría conducir al sobreajuste. Si se establece en un número más pequeño, como 0.6, se utilizará una muestra aleatoria del 60% de las características para entrenar cada árbol, lo que podría ayudar a evitar el sobreajuste.

```{r}
set.seed(50)
# Customización de grid de hiperparámetros
gbmGrid <-  expand.grid(max_depth = c(3, 5, 7), 
                        nrounds = (1:10)*50,    # number of trees
                        # default values below
                        eta = 0.3,
                        gamma = 0,
                        subsample = 1,
                        min_child_weight = 1,
                        colsample_bytree = 0.6)
```

## Entrenamiento del modelo con datos balanceados de entrenamiento

```{r include=FALSE}
options(warn=-1)
model_xgboost_train = train(Outcome~., data = xgboost_train, method = "xgbTree", trControl = train_control, tuneGrid = gbmGrid)

```

```{r}
print(model_xgboost_train)
```

## Predicciones con datos desbalanceados de prueba

```{r}
#use model to make predictions on test data
predicts_xgboost <- predict(model_xgboost_train, xgboost_test)
cm <- caret::confusionMatrix (predicts_xgboost, xgboost_test$Outcome)
cm
```

## Error con datos desbalanceados de prueba

```{r}
overall_accuracy <- cm$overall['Accuracy'] 
# Calcular el error de prueba como 1 - precisión
test_error <- 1 - overall_accuracy
# Imprimir el error de prueba
cat("Error de prueba:", test_error, "\n")
```

## Predicciones con datos desbalanceados de entrenamiento

```{r}
#use model to make predictions on train data
predicts_xgboost <- predict(model_xgboost_train, xgboost_train)
cm <- caret::confusionMatrix (predicts_xgboost, xgboost_train$Outcome)
cm
```

## Error con datos desbalanceados de entenamiento

```{r}
overall_accuracy <- cm$overall['Accuracy'] 
# Calcular el error de entrenamiento como 1 - precisión
train_error <- 1 - overall_accuracy
# Imprimir el error de entrenamiento
cat("Error de entrenamiento:", train_error, "\n")
```

# Conclusiones

-   A continuación se presenta una tabla estatica que puede variar dependiendo de la ejecución

| Modelo                   | Error datos desbalanceados Prueba | Error datos balanceados Entrenamiento |
|-------------------|-------------------------|----------------------------|
| Random Forest Tidymodels | 0.2662338                         | 0.1962617                             |
| XGBoost                  | 0.2597403                         | 0.03738318                            |
| Random Forest H2o        | 0.3051948                         | 0.2313084                             |

Al hacer la comparativa, tiene un performance interesante con datos balanceados tidymodels, pero se comporta mejor con datos desbalanceados XGBoost random forest.

Según el estudio, las variables con mayor importancia para conocer si un paciente tiene o no diabetes son la Glucosa, el indice de masa corportal y la edad.

En el presente estudio se aplicó ingeniería de características para sustituir los datos faltantes, se aplicarón técnicas de sampling, optimización de hiperparámetros por grid search y una exploración de datos estratégica.

# Referencias

Dataset: [Improve variables in data \| Kaggle](https://www.kaggle.com/datasets/whenamancodes/predict-diabities?sort=votes) [RPubs - Datos No Balanceados](https://rpubs.com/Diego_Cortes/749267) [Feature Selection with the Caret R Package - MachineLearningMastery.com](https://machinelearningmastery.com/feature-selection-with-the-caret-r-package/) [11 Subsampling For Class Imbalances \| The caret Package (topepo.github.io)](https://topepo.github.io/caret/subsampling-for-class-imbalances.html) [BOXPLOT en R (Diagrama de Cajas y Bigotes) [GUÍA COMPLETA] (r-coder.com)](https://r-coder.com/boxplot-en-r/) [Introduction to DataExplorer (r-project.org)](https://cran.r-project.org/web/packages/DataExplorer/vignettes/dataexplorer-intro.html) [Remove Duplicate rows in R using Dplyr -- distinct () function - DataScience Made Simple](https://www.datasciencemadesimple.com/remove-duplicate-rows-r-using-dplyr-distinct-function/) [XGBoost R Tutorial --- xgboost 1.7.5 documentation](https://xgboost.readthedocs.io/en/stable/R-package/xgboostPresentation.html)
[Beginners Tutorial on XGBoost and Parameter Tuning in R Tutorials & Notes \| Machine Learning \| HackerEarth](https://www.hackerearth.com/practice/machine-learning/machine-learning-algorithms/beginners-tutorial-on-xgboost-parameter-tuning-r/tutorial/)
