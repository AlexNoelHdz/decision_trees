---
title: "clasificacion_y_regresión"
author: "ANHG"
date: "2023-03-01"
output: html_document
---

```{r}
library(tidyverse)
library(caTools)
library(rpart)
library(rpart.plot)
library(tictoc)
library(beepr)
library(DataExplorer)
```

```{r}
# Cargar los datos
data <- read.csv("data/Movie_regression.csv")
```

## Exploración de datos

```{r}
head(data)
```

```{r}
colnames(data)
```

```{r}
plot_intro(data)
```

```{r}
plot_missing(data)
```

```{r}
summary(data)
```

### Mutar datos a factor para ver la diferencia en el summary

Esto no es estrictamente necesario para la regresión.

```{r}
data <- data %>%  mutate(Genre = as.factor(Genre))
summary(data)
```

## Construcción del modelo

### Split de los datos

```{r}
set.seed(123)
split = sample.split(data, SplitRatio = 0.8)
data_train = subset(data, split == TRUE)
data_test = subset(data, split == FALSE)
```

### Debemos asegurar que la distribución de la salida es similar

```{r}
summary(data_train$Collection)
summary(data_test$Collection)
```

## Creación del modelo del árbol con rpart

```{r}
#Alt guion hace flechita
model_reg <- rpart(formula = Collection~.,
                   data = data_train,
                   control = rpart.control(maxdepth = 3))
model_reg
```

### Visualización del árbol

```{r}
rpart.plot(model_reg, box.palette = "RdBu", digits = -3)
```

### Visualización y cálculo de predicción en test

```{r}
test <- data_test %>% mutate(pred = predict(model_reg, data_test, type = 'vector'),
                             reg = 1: nrow(data_test),
                             dif_pred_coll = Collection - pred)
test
```

```{r}
test %>% ggplot() + geom_point(aes(x = reg, y = dif_pred_coll))
```

### MSE2

```{r}
MSE <- mean((test$pred - test$Collection)^2)^(1/2)
MSE
```

```{r}
data$Collection %>% summary()
```

Poda de los árboles

```{r}
full_tree <- rpart(formula = Collection~.,
                   data = data_train,
                   control = rpart.control(cp = 0) # Cost complexity (0 es el más grande posible)
                   )
```

Visualización del árbol

```{r}
rpart.plot(full_tree, box.palette = 'RdBu', digits = -3)
```

# Comportamiento del cost complexity Cp. (hiperparámetro)

```{r}
printcp(full_tree)
# Para cada nivel de la tabla el xerror y la xstd nos interesan
# Se busca minimizar este error hasta llegar a 0
```

# Verlo en visualización

```{r}
plotcp(full_tree)
```

# Buscamos minimizar, hay una función

## Minimización de xerror

```{r}
full_tree$cptable
```

```{r}
mincp <- full_tree$cptable[which.min(full_tree$cptable[, 'xerror']),"CP"]
mincp
```

```{r}
#podado_tree <- rpart(formula = Collection~.,
     #              data = data_train,
        #           control = rpart.control(cp = mincp))
```

# Poda del árbol:

```{r}
prune_tree <- prune(full_tree, cp = mincp)
rpart.plot(prune_tree, box.palette = 'RdBu', digits = -3)
  
```

# Evaluarlo en el test

```{r}
test$fulltree <- predict(full_tree, data_test, type="vector")
MSE_FULL <- mean((test$fulltree - test$Collection)^2)^(1/2)
# Modelo árbol completo
MSE_FULL
```

```{r}
# Modelo profundidad max_dep de 3
MSE
```

```{r}
test$prune <- predict(prune_tree, data_test, type="vector")
MSE_PRUNE <- mean((test$prune - test$Collection)^2)^(1/2)
# Modelo árbol completo
MSE_PRUNE
```
